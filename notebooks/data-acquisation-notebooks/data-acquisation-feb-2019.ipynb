{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import praw\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a reddit app instance to collect post data from r/india submreddit\n",
    "reddit = praw.Reddit(client_id='u0_eiRibrOBr5w', client_secret='wYMSPOuqFfUGubC81Nnn7eCvIsE', user_agent='reddit-scrap-1', username='macabdul9', password='Sudo$0#1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = reddit.submission(id=\"fxqifi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RSS says Tablighi Jamaat conduct not reflection on all Muslims, theyâ€™re aiding govt in fight'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(url, num_comments):\n",
    "    # get top 20 comments if total comments are more than that\n",
    "    subm = reddit.submission(url=url)\n",
    "\n",
    "    # comments = subm.comments.list()\n",
    "    # if len(comments) > 10:\n",
    "    #     comments = comments[:10]\n",
    "\n",
    "    comments_body = []\n",
    "    sum_score = 0\n",
    "    count = 0\n",
    "    if num_comments > 0:\n",
    "        for i, comment in enumerate(subm.comments.list()):\n",
    "\n",
    "            # There exist some comments which has no body\n",
    "            try : \n",
    "                comments_body.append(comment.body)\n",
    "            except:\n",
    "                comments_body.append('')\n",
    "\n",
    "            # There exist some comments which has not given a score\n",
    "            try:\n",
    "                sum_score += comment.score\n",
    "            except:\n",
    "                sum_score += 0            \n",
    "            count += 1\n",
    "            # We only need 10 comments\n",
    "            if (i+1)%10==0:\n",
    "                break\n",
    "    try:\n",
    "        mean = sum_score/count\n",
    "    except:\n",
    "        mean = 0.0\n",
    "    \n",
    "\n",
    "    return \" \".join(comments_body), mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPushshiftSubData(query, after, before, sub):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&size=2000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'allow_live_comments', 'author', 'author_premium', 'can_mod_post', 'contest_mode', 'created_utc',\n",
    "    'full_link', 'id', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_self', 'is_video',\n",
    "    'link_flair_text', 'locked', 'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
    "    'parent_whitelist_status', 'permalink', 'pinned', 'score', 'selftext', 'send_replies', 'spoiler',\n",
    "    'stickied', 'title', 'total_awards_received', 'url'\n",
    "]\n",
    "custom_features = [\n",
    "    'comments', 'mean_comment_score'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSubData(subm):\n",
    "    \n",
    "    # extracting all information about a submission\n",
    "    feature_values = [subm.get(key) for key in features]    \n",
    "    comments, mean_comment_score = get_comments(subm.get('full_link'), subm.get('num_comments')) \n",
    "    feature_values.append(comments)\n",
    "    feature_values.append(mean_comment_score)\n",
    "    subStats[subm.get('id')] = feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subreddit to query\n",
    "sub='india'\n",
    "\n",
    "#before and after dates\n",
    "after = \"1548979200\"  # Fri, 01 Feb 2019 00:00:00 \n",
    "before = \"1551398399\" # Thu, 28 Feb 2019 23:59:59  \n",
    "query = \"\" # title should have either null string more \n",
    "subCount = 0\n",
    "subStats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1551255137&before=1551398399&subreddit=india\n",
      "2019-02-28 23:56:50\n",
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1551378410&before=1551398399&subreddit=india\n",
      "2019-03-01 05:28:00\n",
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1551398280&before=1551398399&subreddit=india\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = getPushshiftSubData(query, after, before, sub)# Will run until all posts have been gathered \n",
    "# from the 'after' date up until before date\n",
    "while len(data) > 0:\n",
    "    for submission in data:\n",
    "        collectSubData(submission)\n",
    "        subCount+=1\n",
    "    # Calls getPushshiftData() with the created date of the last submission\n",
    "    # print(len(data))\n",
    "    if subCount % 1000 == 0:\n",
    "        print(f'{subCount} submission collected')\n",
    "    print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "    after = data[-1]['created_utc']\n",
    "    data = getPushshiftSubData(query, after, before, sub)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Submissions-Feb-2020.pkl\", \"wb\") as f:\n",
    "    pickle.dump(subStats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=list(subStats.values()), columns = features + custom_features, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Submissions-Feb-2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bitcdd344d0df034a7395ad747f8a4214da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
