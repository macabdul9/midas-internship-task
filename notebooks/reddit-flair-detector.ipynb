{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import praw\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Acquisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We mainly (not limited to) need the following  data about posts to model a flair detector\n",
    "- ID\n",
    "- Title\n",
    "- Body\n",
    "- Comments\n",
    "- URLs\n",
    "- Flair\n",
    "- Other Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ref: https://praw.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a reddit app instance to collect post data from r/india submreddit\n",
    "reddit = praw.Reddit(client_id='xVeb5-ej49aBDg', client_secret='HLuuBB0e1upw1pbZ-oUFtrBplFY', user_agent='reddit-scrap', username='macabdul9', password='Sudo$0#1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pushshit.io api query params to colllect the data\n",
    "\n",
    "def getPushshiftSubData(ids):\n",
    "    # url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    # print(url)\n",
    "    url = \"https://api.pushshift.io/reddit/comment/search?ids=\"+str(ids)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getPushshiftSubData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = reddit.submission(id=\"fxqifi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turn Around Time(TAT) for getting all comments of a post is way higher using praw with submission_id than pushshift.io api comment search below code snippets illustrate the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# comment_ids = []\n",
    "# count = 0\n",
    "# for comment in subm.comments.list():\n",
    "#     comment_ids.append(comment.id)\n",
    "#     print(comment.body)\n",
    "#     count+=1\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# comments = getPushshiftSubData(','.join(comment_ids))\n",
    "# count = 0\n",
    "# for comment in comments:\n",
    "#     print(comment['body'])\n",
    "#     count +=1\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = subm.comments.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.over_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comment in subm.comments.list():\n",
    "#     # print(comment)\n",
    "#     # print(comment.score)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(url):\n",
    "    # get top 20 comments if total comments are more than that\n",
    "    subm = reddit.submission(url=url)\n",
    "\n",
    "    # comments = subm.comments.list()\n",
    "    # if len(comments) > 10:\n",
    "    #     comments = comments[:10]\n",
    "\n",
    "    comments_body = []\n",
    "    sum_score = 0\n",
    "    try:\n",
    "        for i, comment in subm.comments.list():\n",
    "            \n",
    "            # There exist some comments which has no body\n",
    "            try : \n",
    "                comments_body.append(comment.body)\n",
    "            except:\n",
    "                comments_body.append('')\n",
    "            \n",
    "            # There exist some comments which has not a score\n",
    "            try:\n",
    "                sum_score += comment.score\n",
    "            except:\n",
    "                sum_score += 0            \n",
    "            \n",
    "            # We only need 10 comments\n",
    "            if (i+1)%10==0:\n",
    "                break\n",
    "        try:\n",
    "            mean_score = sum_score/10\n",
    "        except:\n",
    "            mean_score = 0\n",
    "    except:\n",
    "        return comments_body, 0.0\n",
    "\n",
    "    return \" \".join(comments_body), mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_comments('https://www.reddit.com/r/india/comments/d0ytzc/nasa_on_twitter_space_is_hard_we_commend_isro_s/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPushshiftSubData(query, after, before, sub):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&size=2000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSubData(subm):\n",
    "    subData = list() #list to store data points\n",
    "    \n",
    "    sub_id = subm['id']\n",
    "    \n",
    "    sub_text = subm['title']\n",
    "    \n",
    "    author = subm['author']\n",
    "    \n",
    "    full_link = subm['full_link']\n",
    "    \n",
    "    permalink = subm['permalink']\n",
    "    \n",
    "    url = subm['url']\n",
    "    \n",
    "    try:\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = \"NaN\"    \n",
    "    \n",
    "    \n",
    "    score = subm['score']\n",
    "    \n",
    "    created = datetime.datetime.fromtimestamp(subm['created_utc']) #1520561700.0\n",
    "    \n",
    "    numComms = subm['num_comments']\n",
    "    \n",
    "    \n",
    "    over_18 = subm['over_18']    \n",
    "    \n",
    "            \n",
    "    comments, mean_comment_score = get_comments(subm['full_link'])    \n",
    "    \n",
    "    subData.append((sub_id, sub_text, author, full_link, permalink, url, flair, score, created, numComms, comments, mean_comment_score, over_18))\n",
    "    \n",
    "    subStats[sub_id] = subData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subreddit to query\n",
    "sub='india'\n",
    "\n",
    "#before and after dates\n",
    "after = \"1577836800\"  # Wed, 01 Jan 2020 00:00:00 \n",
    "before = \"1585699200\" # Wed, 01 Apr 2020 00:00:00 \n",
    "query = \"\" # title should have either null string more \n",
    "subCount = 0\n",
    "subStats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1577836800&before=1585699200&subreddit=india\n",
      "2020-01-03 14:25:07\n",
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1578041707&before=1585699200&subreddit=india\n",
      "2020-01-05 18:32:25\n",
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1578229345&before=1585699200&subreddit=india\n",
      "2020-01-07 11:46:09\n",
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1578377769&before=1585699200&subreddit=india\n"
     ]
    }
   ],
   "source": [
    "data = getPushshiftSubData(query, after, before, sub)# Will run until all posts have been gathered \n",
    "# from the 'after' date up until before date\n",
    "while len(data) > 0:\n",
    "    for submission in data:\n",
    "        collectSubData(submission)\n",
    "        subCount+=1\n",
    "    # Calls getPushshiftData() with the created date of the last submission\n",
    "    # print(len(data))\n",
    "    if (subCount + 1) % 1000 == 0:\n",
    "        print(f'{subCount} submission collected')\n",
    "    print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "    after = data[-1]['created_utc']\n",
    "    data = getPushshiftSubData(query, after, before, sub)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reddit.com/r/india/comments/eib2wt/sunny_leones_popularity_in_the_subcontinent/'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.num_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sunny Leone's popularity in the Subcontinent\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in subm.comments.list():\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python37064bitvenvvirtualenv15d36654ff944964aee51e1ffc378212"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
