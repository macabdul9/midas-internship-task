{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import praw\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Acquisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We mainly (not limited to) need the following  data about posts to model a flair detector\n",
    "- ID\n",
    "- Title\n",
    "- Body\n",
    "- Comments\n",
    "- URLs\n",
    "- Flair\n",
    "- Other Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ref: https://praw.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a reddit app instance to collect post data from r/india submreddit\n",
    "reddit = praw.Reddit(client_id='xVeb5-ej49aBDg', client_secret='HLuuBB0e1upw1pbZ-oUFtrBplFY', user_agent='reddit-scrap', username='macabdul9', password='Sudo$0#1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pushshit.io api query params to colllect the data\n",
    "\n",
    "def getPushshiftSubData(ids):\n",
    "    # url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    # print(url)\n",
    "    url = \"https://api.pushshift.io/reddit/comment/search?ids=\"+str(ids)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getPushshiftSubData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = reddit.submission(id=\"fxqifi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turn Around Time(TAT) for getting all comments of a post is way higher using praw with submission_id than pushshift.io api comment search below code snippets illustrate the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# comment_ids = []\n",
    "# count = 0\n",
    "# for comment in subm.comments.list():\n",
    "#     comment_ids.append(comment.id)\n",
    "#     print(comment.body)\n",
    "#     count+=1\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# comments = getPushshiftSubData(','.join(comment_ids))\n",
    "# count = 0\n",
    "# for comment in comments:\n",
    "#     print(comment['body'])\n",
    "#     count +=1\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = subm.comments.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.over_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comment in subm.comments.list():\n",
    "#     # print(comment)\n",
    "#     # print(comment.score)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(url, num_comments):\n",
    "    # get top 20 comments if total comments are more than that\n",
    "    subm = reddit.submission(url=url)\n",
    "\n",
    "    # comments = subm.comments.list()\n",
    "    # if len(comments) > 10:\n",
    "    #     comments = comments[:10]\n",
    "\n",
    "    comments_body = []\n",
    "    sum_score = 0\n",
    "    if num_comments > 0:\n",
    "        for i, comment in enumerate(subm.comments.list()):\n",
    "\n",
    "            # There exist some comments which has no body\n",
    "            try : \n",
    "                comments_body.append(comment.body)\n",
    "            except:\n",
    "                comments_body.append('')\n",
    "\n",
    "            # There exist some comments which has not given a score\n",
    "            try:\n",
    "                sum_score += comment.score\n",
    "            except:\n",
    "                sum_score += 0            \n",
    "\n",
    "            # We only need 10 comments\n",
    "            if (i+1)%10==0:\n",
    "                break\n",
    "    \n",
    "\n",
    "    return \" \".join(comments_body), sum_score/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_comments('https://www.reddit.com/r/india/comments/d0ytzc/nasa_on_twitter_space_is_hard_we_commend_isro_s/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPushshiftSubData(query, after, before, sub):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&size=2000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSubData(subm):\n",
    "    subData = list() #list to store data points\n",
    "    \n",
    "    sub_id = subm['id']\n",
    "    \n",
    "    sub_text = subm['title']\n",
    "    \n",
    "    author = subm['author']\n",
    "    \n",
    "    full_link = subm['full_link']\n",
    "    \n",
    "    permalink = subm['permalink']\n",
    "    \n",
    "    url = subm['url']\n",
    "    \n",
    "    try:\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = \"NaN\"    \n",
    "    \n",
    "    \n",
    "    score = subm['score']\n",
    "    \n",
    "    created = datetime.datetime.fromtimestamp(subm['created_utc']) #1520561700.0\n",
    "    \n",
    "    numComms = subm['num_comments']\n",
    "    \n",
    "    \n",
    "    over_18 = subm['over_18']    \n",
    "    \n",
    "            \n",
    "    comments, mean_comment_score = get_comments(subm['full_link'], numComms)    \n",
    "    \n",
    "    subData.append((sub_id, sub_text, author, full_link, permalink, url, flair, score, created, numComms, comments, mean_comment_score, over_18))\n",
    "    \n",
    "    subStats[sub_id] = subData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subreddit to query\n",
    "sub='india'\n",
    "\n",
    "#before and after dates\n",
    "after = \"1577836800\"  # Wed, 01 Jan 2020 00:00:00 \n",
    "before = \"1586476800\" # Fri, 10 Apr 2020 00:00:00  \n",
    "query = \"\" # title should have either null string more \n",
    "subCount = 0\n",
    "subStats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?title=&size=2000&after=1578041707&before=1586476800&subreddit=india\n"
     ]
    }
   ],
   "source": [
    "data = getPushshiftSubData(query, after, before, sub)# Will run until all posts have been gathered \n",
    "# from the 'after' date up until before date\n",
    "while len(data) > 0:\n",
    "    for submission in data:\n",
    "        collectSubData(submission)\n",
    "        subCount+=1\n",
    "    # Calls getPushshiftData() with the created date of the last submission\n",
    "    # print(len(data))\n",
    "    if subCount % 1000 == 0:\n",
    "        print(f'{subCount} submission collected')\n",
    "    print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "    after = data[-1]['created_utc']\n",
    "    data = getPushshiftSubData(query, after, before, sub)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3435"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subStatsCopy = subStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SubmissionS-Jan-March-2020.pkl\", \"wb\") as f:\n",
    "    pickle.dump(subStats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42830 submissions have added to list\n",
      "1st entry is:\n",
      "Sunny Leone's popularity in the Subcontinent created: https://i.redd.it/v9xizr4f62841.jpg\n",
      "Last entry is:\n",
      "Coronavirus outbreak timeline created: https://youtu.be/J9Z12Ts7yRA\n"
     ]
    }
   ],
   "source": [
    "print(str(len(subStats)) + \" submissions have added to list\")\n",
    "print(\"1st entry is:\")\n",
    "print(list(subStats.values())[0][0][1] + \" created: \" + str(list(subStats.values())[0][0][5]))\n",
    "print(\"Last entry is:\")\n",
    "print(list(subStats.values())[-1][0][1] + \" created: \" + str(list(subStats.values())[-1][0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateSubs_file():\n",
    "    upload_count = 0\n",
    "    \n",
    "    print(\"input filename of submission file, please add .csv\")\n",
    "    filename = input()\n",
    "    file = filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as file: \n",
    "        a = csv.writer(file, delimiter=',')\n",
    "        headers = [\"sub_id\", \"sub_text\", \"author\", \"full_link\", \"permalink\", \"url\", \"flair\", \"score\", \"created\", \"numComms\", \"comments\", \"mean_comment_score\", \"over_18\"]\n",
    "        a.writerow(headers)\n",
    "        for sub in subStats:\n",
    "            a.writerow(subStats[sub][0])\n",
    "            upload_count+=1\n",
    "            \n",
    "        print(str(upload_count) + \" submissions have been uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input filename of submission file, please add .csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " submission.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 submissions have been uploaded\n"
     ]
    }
   ],
   "source": [
    "updateSubs_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python37064bitvenvvirtualenv15d36654ff944964aee51e1ffc378212"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
